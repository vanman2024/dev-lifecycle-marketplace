# Google Gemini API - Complete Guide for Image & Video Generation

**Last Updated:** November 9, 2025

## üìö **Official Documentation Links**

### **Main Documentation**

- [Gemini API Overview](https://ai.google.dev/gemini-api/docs)
- [Gemini API Quickstart](https://ai.google.dev/gemini-api/docs/quickstart)
- [API Keys Documentation](https://ai.google.dev/gemini-api/docs/api-key)
- [Libraries & SDKs](https://ai.google.dev/gemini-api/docs/libraries)
- [API Reference](https://ai.google.dev/api)

### **Image Generation Documentation**

#### **Gemini Native Image Generation (Nano Banana)**

- [Image Generation with Gemini (Nano Banana)](https://ai.google.dev/gemini-api/docs/image-generation)
- [Image Understanding](https://ai.google.dev/gemini-api/docs/image-understanding)

#### **Imagen Models**

- [Generate Images using Imagen](https://ai.google.dev/gemini-api/docs/imagen)
- [Imagen Technology (DeepMind)](https://deepmind.google/technologies/imagen-3/)

### **Video Generation Documentation**

- [Generate Videos with Veo 3.1](https://ai.google.dev/gemini-api/docs/video)
- [Veo Models (DeepMind)](https://deepmind.google/models/veo/)
- [Video Understanding](https://ai.google.dev/gemini-api/docs/video-understanding)

### **Model Documentation**

- [Gemini Models Overview](https://ai.google.dev/gemini-api/docs/models)
- [Gemini Models (Detailed)](https://ai.google.dev/gemini-api/docs/models/gemini)
- [Embeddings](https://ai.google.dev/gemini-api/docs/embeddings)
- [Robotics Overview](https://ai.google.dev/gemini-api/docs/robotics-overview)

### **Additional Models**

- [Lyria (Music Generation)](https://ai.google.dev/gemini-api/docs/music-generation)

### **Core Capabilities**

- [Text Generation](https://ai.google.dev/gemini-api/docs/text-generation)
- [Document Processing](https://ai.google.dev/gemini-api/docs/document-processing)
- [Speech and Audio](https://ai.google.dev/gemini-api/docs/audio)
- [Thinking Mode](https://ai.google.dev/gemini-api/docs/thinking)
- [Structured Output](https://ai.google.dev/gemini-api/docs/structured-output)
- [Function Calling](https://ai.google.dev/gemini-api/docs/function-calling)
- [Long Context](https://ai.google.dev/gemini-api/docs/long-context)

### **Tools & Features**

- [Google Search Integration](https://ai.google.dev/gemini-api/docs/google-search)
- [Google Maps Grounding](https://ai.google.dev/gemini-api/docs/maps-grounding)
- [Code Execution](https://ai.google.dev/gemini-api/docs/code-execution)
- [URL Context](https://ai.google.dev/gemini-api/docs/url-context)
- [Computer Use](https://ai.google.dev/gemini-api/docs/computer-use)
- [File Search](https://ai.google.dev/gemini-api/docs/file-search)

### **Live API**

- [Live API - Get Started](https://ai.google.dev/gemini-api/docs/live)
- [Live API Capabilities](https://ai.google.dev/gemini-api/docs/live-guide)
- [Live API Tool Use](https://ai.google.dev/gemini-api/docs/live-tools)
- [Session Management](https://ai.google.dev/gemini-api/docs/live-session)
- [Ephemeral Tokens](https://ai.google.dev/gemini-api/docs/ephemeral-tokens)

### **Advanced Features**

- [Batch API](https://ai.google.dev/gemini-api/docs/batch-api)
- [Files API](https://ai.google.dev/gemini-api/docs/files)
- [Context Caching](https://ai.google.dev/gemini-api/docs/caching)
- [Token Counting](https://ai.google.dev/gemini-api/docs/tokens)

### **Best Practices & Guides**

- [Prompt Engineering](https://ai.google.dev/gemini-api/docs/prompting-strategies)
- [Introduction to Prompt Design](https://ai.google.dev/gemini-api/docs/prompting-intro)
- [Logs and Datasets](https://ai.google.dev/gemini-api/docs/logs-datasets)
- [Data Logging and Sharing Policy](https://ai.google.dev/gemini-api/docs/logs-policy)

### **Safety & Security**

- [Safety Settings](https://ai.google.dev/gemini-api/docs/safety-settings)
- [SynthID Watermarking](https://ai.google.dev/responsible/docs/safeguards/synthid)
- [SynthID Technology (DeepMind)](https://deepmind.google/technologies/synthid/)
- [SynthID Verification Platform](https://deepmind.google/science/synthid/)

### **OpenAI Compatibility**

- [OpenAI Compatibility Guide](https://ai.google.dev/gemini-api/docs/openai)

### **Pricing & Limits**

- [Pricing Information](https://ai.google.dev/gemini-api/docs/pricing)
- [Rate Limits](https://ai.google.dev/gemini-api/docs/rate-limits)
- [Billing Information](https://ai.google.dev/gemini-api/docs/billing)

### **Migration & Updates**

- [Migrate to Gen AI SDK](https://ai.google.dev/gemini-api/docs/migrate)
- [Release Notes](https://ai.google.dev/gemini-api/docs/changelog)
- [Deprecations](https://ai.google.dev/gemini-api/docs/deprecations)

### **Troubleshooting & Support**

- [API Troubleshooting](https://ai.google.dev/gemini-api/docs/troubleshooting)
- [Community Forum](https://discuss.ai.google.dev/c/gemini-api/)

### **Fine-tuning**

- [Model Fine-tuning](https://ai.google.dev/gemini-api/docs/model-tuning)

### **Google AI Studio**

- [Get API Key (AI Studio)](https://aistudio.google.com/apikey)
- [AI Studio](https://aistudio.google.com/)
- [Veo Studio Applet](https://aistudio.google.com/apps/bundled/veo_studio)
- [Start Building with Gemini](https://aistudio.google.com/apps)

### **Policies**

- [Terms of Service](https://ai.google.dev/gemini-api/terms)
- [Available Regions](https://ai.google.dev/gemini-api/docs/available-regions)
- [Usage Policies](https://ai.google.dev/gemini-api/docs/usage-policies)
- [Prohibited Use Policy](https://policies.google.com/terms/generative-ai/use-policy)
- [Abuse Monitoring](https://ai.google.dev/gemini-api/docs/usage-policies#abuse-monitoring)

### **Developer Resources**

- [Google Developers Site Policies](https://developers.google.com/site-policies)
- [Creative Commons Attribution 4.0 License](https://creativecommons.org/licenses/by/4.0/)
- [Apache 2.0 License](https://www.apache.org/licenses/LICENSE-2.0)

---

## üêç **Python SDK Documentation**

### **GitHub Repositories**

- [Google Gen AI Python SDK (Main)](https://github.com/googleapis/python-genai)
- [Python GenAI - README](https://github.com/googleapis/python-genai/blob/main/README.md)
- [Python GenAI - Documentation](https://github.com/googleapis/python-genai/blob/main/docs/_sources/index.rst.txt)
- [Codegen Instructions](https://github.com/googleapis/python-genai/blob/main/codegen_instructions.md)

### **SDK Documentation Sites**

- [Google Gen AI Python SDK Docs](https://googleapis.github.io/python-genai/)

### **Package Information**

- [PyPI - google-genai](https://pypi.org/project/google-genai/)

---

## üìñ **Code Examples & Cookbooks**

### **Official Cookbook**

- [Gemini Cookbook (GitHub)](https://github.com/google-gemini/cookbook)
- [Veo Quickstart Colab](https://colab.research.google.com/github/google-gemini/cookbook/blob/main/quickstarts/Get_started_Veo.ipynb)
- [Image Output Cookbook Guide](https://colab.sandbox.google.com/github/google-gemini/cookbook/blob/main/quickstarts/Image_out.ipynb)

---

## üé® **Image Generation - "Nano Banana" (Gemini 2.5 Flash Image)**

### **Model Information**

- **Model ID:** `gemini-2.5-flash-image`
- **Nickname:** "Nano Banana"
- **Status:** Preview (Production usage allowed)

### **Key Features**

- Text-to-Image generation
- Image editing (text-and-image-to-image)
- Multi-image composition
- Style transfer
- Iterative conversational editing
- High-fidelity text rendering in images
- Interleaved text and image output

### **Python Code Example - Basic Generation**

```python
from google import genai
from google.genai import types
from PIL import Image

client = genai.Client()

prompt = "Create a picture of a nano banana dish in a fancy restaurant with a Gemini theme"

response = client.models.generate_content(
    model="gemini-2.5-flash-image",
    contents=[prompt],
)

for part in response.parts:
    if part.text is not None:
        print(part.text)
    elif part.inline_data is not None:
        image = part.as_image()
        image.save("generated_image.png")
```

### **Python Code Example - Image Editing**

```python
from google import genai
from PIL import Image

client = genai.Client()

prompt = "Create a picture of my cat eating a nano-banana in a fancy restaurant under the Gemini constellation"
image = Image.open("/path/to/cat_image.png")

response = client.models.generate_content(
    model="gemini-2.5-flash-image",
    contents=[prompt, image],
)

for part in response.parts:
    if part.text is not None:
        print(part.text)
    elif part.inline_data is not None:
        image = part.as_image()
        image.save("generated_image.png")
```

### **Python Code Example - Chat Mode for Iterative Editing**

```python
from google import genai
from PIL import Image
from io import BytesIO

client = genai.Client()

prompt = "Create a picture of my cat eating a nano-banana in a fancy restaurant"
image = Image.open('/path/to/image.png')

# Create the chat
chat = client.chats.create(model='gemini-2.5-flash-image')

# Send the image and ask for it to be edited
response = chat.send_message([prompt, image])

# Get the text and the image generated
for i, part in enumerate(response.candidates[0].content.parts):
    if part.text is not None:
        print(part.text)
    elif part.inline_data is not None:
        image = Image.open(BytesIO(part.inline_data.data))
        image.save(f'generated_image_{i}.png')

# Continue iterating
chat.send_message('Can you make it a bananas foster?')
```

### **Configuration Options**

```python
from google.genai import types

response = client.models.generate_content(
    model='gemini-2.5-flash-image',
    contents='A cartoon infographic for flying sneakers',
    config=types.GenerateContentConfig(
        response_modalities=["IMAGE"],  # Image-only output
        image_config=types.ImageConfig(
            aspect_ratio="9:16",  # 1:1, 2:3, 3:2, 3:4, 4:3, 4:5, 5:4, 9:16, 16:9, 21:9
        ),
    ),
)
```

### **Supported Aspect Ratios & Resolutions**

| Aspect Ratio | Resolution | Tokens |
| ------------ | ---------- | ------ |
| 1:1          | 1024x1024  | 1290   |
| 2:3          | 832x1248   | 1290   |
| 3:2          | 1248x832   | 1290   |
| 3:4          | 864x1184   | 1290   |
| 4:3          | 1184x864   | 1290   |
| 4:5          | 896x1152   | 1290   |
| 5:4          | 1152x896   | 1290   |
| 9:16         | 768x1344   | 1290   |
| 16:9         | 1344x768   | 1290   |
| 21:9         | 1536x672   | 1290   |

### **Pricing**

- **Cost:** Token-based pricing at $30 per 1 million tokens
- **Image Output:** 1290 tokens per image (flat rate up to 1024x1024px)

---

## üñºÔ∏è **Imagen Models (Specialized Image Generation)**

### **Available Models**

- **Imagen 4.0 Standard:** `imagen-4.0-generate-001`
- **Imagen 4.0 Ultra:** `imagen-4.0-ultra-generate-001` (highest quality)
- **Imagen 4.0 Fast:** `imagen-4.0-fast-generate-001` (optimized speed)
- **Imagen 3.0:** `imagen-3.0-generate-002`

### **Key Features**

- Photorealistic image quality
- Advanced text rendering and typography
- Multiple images per request (1-4 images)
- Aspect ratio control
- Person generation controls
- SynthID watermarking (automatic)

### **Python Code Example**

```python
from google import genai
from google.genai import types

client = genai.Client()

response = client.models.generate_images(
    model='imagen-4.0-generate-001',
    prompt='Robot holding a red skateboard',
    config=types.GenerateImagesConfig(
        number_of_images=4,  # 1 to 4 (always 1 for ultra model)
        image_size='1K',  # '1K' or '2K' (Standard and Ultra only)
        aspect_ratio='1:1',  # '1:1', '3:4', '4:3', '9:16', '16:9'
        person_generation='allow_adult',  # 'dont_allow', 'allow_adult', 'allow_all'
    ),
)

for generated_image in response.generated_images:
    generated_image.image.show()
```

### **Configuration Parameters**

- **numberOfImages:** 1 to 4 (inclusive), default is 4
- **imageSize:** `1K` or `2K` (only for Standard and Ultra models), default is `1K`
- **aspectRatio:** `"1:1"`, `"3:4"`, `"4:3"`, `"9:16"`, `"16:9"`, default is `"1:1"`
- **personGeneration:**
  - `"dont_allow"`: Block generation of images of people
  - `"allow_adult"`: Generate images of adults, but not children (default)
  - `"allow_all"`: Generate images including adults and children (NOT allowed in EU, UK, CH, MENA)

### **Pricing**

- **Cost:** $0.02/image to $0.12/image (depending on model variant)

### **Upscaling (Vertex AI Only)**

```python
response2 = client.models.upscale_image(
    model='imagen-3.0-generate-001',
    image=response1.generated_images[0].image,
    upscale_factor='x2',
    config=types.UpscaleImageConfig(
        include_rai_reason=True,
        output_mime_type='image/jpeg',
    ),
)
response2.generated_images[0].image.show()
```

### **Image Editing (Vertex AI Only)**

```python
from google.genai import types
from google.genai.types import RawReferenceImage, MaskReferenceImage

raw_ref_image = RawReferenceImage(
    reference_id=1,
    reference_image=response1.generated_images[0].image,
)

mask_ref_image = MaskReferenceImage(
    reference_id=2,
    config=types.MaskReferenceConfig(
        mask_mode='MASK_MODE_BACKGROUND',
        mask_dilation=0,
    ),
)

response3 = client.models.edit_image(
    model='imagen-3.0-capability-001',
    prompt='Sunlight and clear sky',
    reference_images=[raw_ref_image, mask_ref_image],
    config=types.EditImageConfig(
        edit_mode='EDIT_MODE_INPAINT_INSERTION',
        number_of_images=1,
        include_rai_reason=True,
        output_mime_type='image/jpeg',
    ),
)
response3.generated_images[0].image.show()
```

---

## üé¨ **Video Generation with Veo 3.1**

### **Available Models**

- **Veo 3.1 Preview:** `veo-3.1-generate-preview` (8s, 720p/1080p, with audio)
- **Veo 3.1 Fast Preview:** `veo-3.1-fast-generate-preview` (optimized for speed)
- **Veo 3.0:** `veo-3.0-generate-001` (stable)
- **Veo 3.0 Fast:** `veo-3.0-fast-generate-001` (stable, fast)
- **Veo 2.0:** `veo-2.0-generate-001`

### **Key Features**

- **Native audio generation** (dialogue, sound effects, ambient noise)
- **Video extension:** Extend Veo-generated videos by 7 seconds (up to 20 times)
- **Frame-specific generation:** Specify first and last frames (interpolation)
- **Reference images:** Use up to 3 reference images to guide content (Veo 3.1 only)
- **Image-to-video:** Animate static images
- **Video-to-video:** Extend or transform existing videos (Vertex AI only)
- **Resolution:** 720p and 1080p at 24fps
- **Duration:** 4, 6, or 8 seconds

### **Python Code Example - Text-to-Video**

```python
import time
from google import genai
from google.genai import types

client = genai.Client()

prompt = """A close up of two people staring at a cryptic drawing on a wall,
torchlight flickering. A man murmurs, 'This must be it. That's the secret code.'
The woman looks at him and whispering excitedly, 'What did you find?'"""

operation = client.models.generate_videos(
    model="veo-3.1-generate-preview",
    prompt=prompt,
)

# Poll the operation status until the video is ready
while not operation.done:
    print("Waiting for video generation to complete...")
    time.sleep(10)
    operation = client.operations.get(operation)

# Download the generated video
generated_video = operation.response.generated_videos[0]
client.files.download(file=generated_video.video)
generated_video.video.save("dialogue_example.mp4")
print("Generated video saved to dialogue_example.mp4")
```

### **Python Code Example - Image-to-Video (with Nano Banana)**

```python
import time
from google import genai

client = genai.Client()

prompt = "Panning wide shot of a calico kitten sleeping in the sunshine"

# Step 1: Generate an image with Nano Banana
image = client.models.generate_content(
    model="gemini-2.5-flash-image",
    contents=prompt,
    config={"response_modalities": ['IMAGE']}
)

# Step 2: Generate video with Veo 3.1 using the image
operation = client.models.generate_videos(
    model="veo-3.1-generate-preview",
    prompt=prompt,
    image=image.parts[0].as_image(),
)

# Poll the operation status until the video is ready
while not operation.done:
    print("Waiting for video generation to complete...")
    time.sleep(10)
    operation = client.operations.get(operation)

# Download the video
video = operation.response.generated_videos[0]
client.files.download(file=video.video)
video.video.save("veo3_with_image_input.mp4")
print("Generated video saved to veo3_with_image_input.mp4")
```

### **Python Code Example - Video Extension**

```python
import time
from google import genai
from google.genai import types

client = genai.Client()

prompt = "Track the butterfly into the garden as it lands on an orange origami flower. A fluffy white puppy runs up and gently pats the flower."

operation = client.models.generate_videos(
    model="veo-3.1-generate-preview",
    video=butterfly_video,  # Previously generated Veo video
    prompt=prompt,
    config=types.GenerateVideosConfig(
        number_of_videos=1,
        resolution="720p"
    ),
)

# Poll the operation status until the video is ready
while not operation.done:
    print("Waiting for video generation to complete...")
    time.sleep(10)
    operation = client.operations.get(operation)

# Download the video
video = operation.response.generated_videos[0]
client.files.download(file=video.video)
video.video.save("veo3.1_extension.mp4")
print("Generated video saved to veo3.1_extension.mp4")
```

### **Python Code Example - Using Reference Images (Veo 3.1 Only)**

```python
import time
from google import genai
from google.genai import types

client = genai.Client()

prompt = """The video opens with a medium, eye-level shot of a beautiful woman
with dark hair and warm brown eyes. She wears a magnificent, high-fashion flamingo
dress with layers of pink and fuchsia feathers, complemented by whimsical pink,
heart-shaped sunglasses. She walks with serene confidence through the crystal-clear,
shallow turquoise water of a sun-drenched lagoon."""

dress_reference = types.VideoGenerationReferenceImage(
    image=dress_image,  # Generated separately with Nano Banana
    reference_type="asset"
)

sunglasses_reference = types.VideoGenerationReferenceImage(
    image=glasses_image,  # Generated separately with Nano Banana
    reference_type="asset"
)

woman_reference = types.VideoGenerationReferenceImage(
    image=woman_image,  # Generated separately with Nano Banana
    reference_type="asset"
)

operation = client.models.generate_videos(
    model="veo-3.1-generate-preview",
    prompt=prompt,
    config=types.GenerateVideosConfig(
        reference_images=[dress_reference, sunglasses_reference, woman_reference],
    ),
)

# Poll the operation status until the video is ready
while not operation.done:
    print("Waiting for video generation to complete...")
    time.sleep(10)
    operation = client.operations.get(operation)

# Download the video
video = operation.response.generated_videos[0]
client.files.download(file=video.video)
video.video.save("veo3.1_with_reference_images.mp4")
print("Generated video saved to veo3.1_with_reference_images.mp4")
```

### **Python Code Example - First and Last Frame Interpolation (Veo 3.1 Only)**

```python
import time
from google import genai
from google.genai import types

client = genai.Client()

prompt = """A cinematic, haunting video. A ghostly woman with long white hair
and a flowing dress swings gently on a rope swing beneath a massive, gnarled tree
in a foggy, moonlit clearing. The fog thickens and swirls around her, and she
slowly fades away, vanishing completely. The empty swing is left swaying
rhythmically on its own in the eerie silence."""

operation = client.models.generate_videos(
    model="veo-3.1-generate-preview",
    prompt=prompt,
    image=first_image,  # Generated separately with Nano Banana
    config=types.GenerateVideosConfig(
        last_frame=last_image  # Generated separately with Nano Banana
    ),
)

# Poll the operation status until the video is ready
while not operation.done:
    print("Waiting for video generation to complete...")
    time.sleep(10)
    operation = client.operations.get(operation)

# Download the video
video = operation.response.generated_videos[0]
client.files.download(file=video.video)
video.video.save("veo3.1_with_interpolation.mp4")
print("Generated video saved to veo3.1_with_interpolation.mp4")
```

### **Configuration Parameters**

```python
from google.genai import types

config = types.GenerateVideosConfig(
    aspect_ratio="16:9",  # "16:9" or "9:16"
    resolution="720p",  # "720p" or "1080p" (1080p only for 8s duration)
    duration_seconds=8,  # 4, 6, or 8 seconds
    person_generation="allow_all",  # "allow_all" or "allow_adult"
    negative_prompt="cartoon, drawing, low quality",  # What NOT to include
    number_of_videos=1,  # Only 1 supported for Veo 3.1
)
```

### **API Parameters Table**

| Parameter          | Description                            | Veo 3.1 & 3.1 Fast            | Veo 3 & 3 Fast             | Veo 2                                    |
| ------------------ | -------------------------------------- | ----------------------------- | -------------------------- | ---------------------------------------- |
| `prompt`           | Text description (supports audio cues) | string                        | string                     | string                                   |
| `negativePrompt`   | What not to include                    | string                        | string                     | string                                   |
| `image`            | Initial image to animate               | Image object                  | Image object               | Image object                             |
| `lastFrame`        | Final frame for interpolation          | Image object                  | Image object               | Image object                             |
| `referenceImages`  | Up to 3 reference images               | VideoGenerationReferenceImage | n/a                        | n/a                                      |
| `video`            | Video for extension                    | Video object                  | n/a                        | n/a                                      |
| `aspectRatio`      | Video aspect ratio                     | "16:9", "9:16"                | "16:9", "9:16"             | "16:9", "9:16"                           |
| `resolution`       | Output resolution                      | "720p", "1080p"               | "720p", "1080p"            | "720p"                                   |
| `durationSeconds`  | Video length                           | 4, 6, 8                       | 4, 6, 8                    | 5, 6, 8                                  |
| `personGeneration` | People generation control              | "allow_all", "allow_adult"    | "allow_all", "allow_adult" | "allow_all", "allow_adult", "dont_allow" |

### **Audio Generation (Veo 3.x)**

Veo 3 models natively generate audio including:

- **Dialogue:** Use quotes for speech: `A man murmurs, 'This must be it.'`
- **Sound Effects:** Describe explicitly: `tires screeching loudly, engine roaring`
- **Ambient Noise:** Describe soundscape: `A faint, eerie hum resonates in the background`

### **Limitations**

- **Request latency:** Min: 11 seconds; Max: 6 minutes (during peak hours)
- **Regional limitations:** In EU, UK, CH, MENA locations, only `allow_adult` for Veo 3
- **Video retention:** Generated videos stored for 2 days, then removed
- **Watermarking:** All videos watermarked with SynthID
- **Safety filters:** Applied to prevent offensive content
- **Audio blocking:** Veo 3.1 may block generation due to safety filters on audio

### **Model Features Comparison**

| Feature                | Veo 3.1 & 3.1 Fast | Veo 3 & 3 Fast | Veo 2          |
| ---------------------- | ------------------ | -------------- | -------------- |
| **Audio**              | ‚úîÔ∏è Always on       | ‚úîÔ∏è Always on   | ‚ùå Silent only |
| **Input Modalities**   | Text, Image, Video | Text, Image    | Text, Image    |
| **Resolution**         | 720p & 1080p       | 720p & 1080p   | 720p           |
| **Frame Rate**         | 24fps              | 24fps          | 24fps          |
| **Duration**           | 4s, 6s, 8s         | 4s, 6s, 8s     | 5s, 6s, 8s     |
| **Videos per Request** | 1                  | 1              | 1 or 2         |
| **Status**             | Preview            | Stable         | Stable         |

---

## üÜö **Comparison: Imagen vs Nano Banana vs Veo**

| Feature              | Imagen 4                          | Gemini Native (Nano Banana)                     | Veo 3.1                                           |
| -------------------- | --------------------------------- | ----------------------------------------------- | ------------------------------------------------- |
| **Best For**         | Photorealistic images, typography | Conversational image editing                    | Video generation with audio                       |
| **Availability**     | Generally available               | Preview (production allowed)                    | Preview                                           |
| **Latency**          | Low (optimized)                   | Higher (more computation)                       | 11s - 6 minutes                                   |
| **Cost**             | $0.02-$0.12/image                 | Token-based ($30/1M tokens)                     | Usage-based pricing                               |
| **Output**           | Images only                       | Images + text interleaved                       | Video with native audio                           |
| **Special Features** | Ultra quality mode, 2K resolution | Multi-turn editing, style transfer, composition | Audio dialogue, video extension, reference images |
| **Editing**          | Upscale & inpaint (Vertex AI)     | Conversational, mask-free                       | Frame interpolation, extension                    |

---

## üéØ **Prompting Best Practices**

### **For Image Generation (Nano Banana)**

1. **Describe the scene, don't list keywords**

   - ‚ùå Bad: "cat, restaurant, fancy, banana"
   - ‚úÖ Good: "A photorealistic close-up of a fluffy ginger cat eating a gourmet banana dessert in an upscale restaurant with soft ambient lighting"

2. **Use photography terminology**

   - Camera angles: "close-up", "wide shot", "aerial view", "eye-level"
   - Lens types: "35mm", "macro lens", "wide-angle", "fisheye"
   - Lighting: "natural lighting", "golden hour", "dramatic shadows", "soft focus"

3. **Specify style clearly**

   - Art styles: "photorealistic", "watercolor painting", "digital art", "art deco"
   - Aesthetic: "minimalist", "vintage", "futuristic", "cyberpunk"

4. **For text in images**

   - Keep text under 25 characters
   - Use 2-3 distinct phrases maximum
   - Specify font style descriptively: "bold modern font", "elegant serif"

5. **Iterate progressively**
   - Start with core concept
   - Add details incrementally
   - Use chat mode for conversational refinement

### **For Video Generation (Veo)**

1. **Include essential elements**

   - **Subject:** What/who is in the video
   - **Action:** What the subject is doing
   - **Style:** Visual aesthetic (cinematic, cartoon, noir)
   - **Camera:** Position and movement (optional)
   - **Ambiance:** Lighting and mood (optional)

2. **Audio prompting (Veo 3.x)**

   - Use quotes for dialogue: `"This must be the key," he murmured`
   - Describe sound effects: `tires screeching, glass shattering`
   - Set ambient tone: `soft jazz music in the background`

3. **Camera control**

   - Motion: "dolly shot", "tracking shot", "zoom in slowly"
   - Position: "aerial view", "worm's eye view", "over-the-shoulder"
   - Composition: "wide shot", "close-up", "medium shot"

4. **Negative prompts**

   - ‚ùå Don't use: "no walls", "don't show people"
   - ‚úÖ Do use: "wall, frame", "empty scene, no characters"

5. **For video extension**
   - Describe continuation naturally
   - Reference the last second of content
   - Voice is only effectively extended if present in last 1 second

---

## üîß **Installation & Setup**

### **Install Python SDK**

```bash
pip install google-genai
```

### **Initialize Client (Developer API)**

```python
from google import genai

# Using API key
client = genai.Client(api_key='YOUR_API_KEY')
```

### **Initialize Client (Vertex AI)**

```python
from google import genai

# Using Vertex AI
client = genai.Client(
    vertexai=True,
    project='my-project-id',
    location='us-central1'
)
```

### **Get API Key**

- Visit [AI Studio](https://aistudio.google.com/apikey) to get your API key

---

## üìä **Additional Resources**

### **GitHub Repositories**

- [Python GenAI SDK](https://github.com/googleapis/python-genai)
- [Gemini Cookbook](https://github.com/google-gemini/cookbook)
- [GenAI Processors](https://github.com/google-gemini/genai-processors)

### **Package Managers**

- [PyPI - google-genai](https://pypi.org/project/google-genai/)
- [NPM - @google/generative-ai](https://www.npmjs.com/package/@google/generative-ai)

### **Community**

- [Gemini API Community Forum](https://discuss.ai.google.dev/c/gemini-api/)
- [Stack Overflow - gemini-api tag](https://stackoverflow.com/questions/tagged/gemini-api)

### **Google Cloud Platform**

- [Vertex AI Documentation](https://cloud.google.com/vertex-ai/docs)
- [Generative AI on Vertex AI](https://cloud.google.com/vertex-ai/docs/generative-ai/learn/overview)

### **Context7 Library IDs**

- Google Gen AI Python SDK: `/googleapis/python-genai`
- Google Gen AI JavaScript SDK: `/googleapis/js-genai`
- Google Gen AI Go SDK: `/googleapis/go-genai`

---

## üîê **Privacy & Watermarking**

### **SynthID Watermarking**

- All images generated by Imagen include [SynthID watermarking](https://deepmind.google/technologies/synthid/)
- All videos generated by Veo include [SynthID watermarking](https://deepmind.google/technologies/synthid/)
- Watermarks are imperceptible but can be detected
- Verification available at [SynthID Platform](https://deepmind.google/science/synthid/)

### **Data Privacy**

- Review [Data Logging and Sharing Policy](https://ai.google.dev/gemini-api/docs/logs-policy)
- Check [Usage Policies](https://ai.google.dev/gemini-api/docs/usage-policies)
- Understand [Terms of Service](https://ai.google.dev/gemini-api/terms)

---

## üí∞ **Pricing Summary**

### **Imagen**

- **Standard:** $0.02 - $0.04 per image
- **Ultra:** $0.08 - $0.12 per image
- **Fast:** Lower cost tier

### **Gemini Native Image (Nano Banana)**

- **Token-based:** $30 per 1 million tokens
- **Image output:** 1290 tokens per image (flat rate)
- **Effective cost:** ~$0.039 per image

### **Veo**

- Check [Pricing Page](https://ai.google.dev/gemini-api/docs/pricing) for current rates
- Varies by model (3.1, 3.0, Fast variants)
- Based on duration and resolution

### **Rate Limits**

- View [Rate Limits Documentation](https://ai.google.dev/gemini-api/docs/rate-limits)
- Limits vary by model and tier

---

## üìù **License Information**

- **Documentation:** [Creative Commons Attribution 4.0 License](https://creativecommons.org/licenses/by/4.0/)
- **Code Samples:** [Apache 2.0 License](https://www.apache.org/licenses/LICENSE-2.0)
- **SDK:** Check individual repository licenses

---

## üöÄ **Quick Start Summary**

### **1. Get API Key**

```bash
# Visit: https://aistudio.google.com/apikey
```

### **2. Install SDK**

```bash
pip install google-genai
```

### **3. Generate Image**

```python
from google import genai
client = genai.Client(api_key='YOUR_KEY')
response = client.models.generate_content(
    model="gemini-2.5-flash-image",
    contents="A serene mountain landscape at sunset",
)
response.parts[0].as_image().save("image.png")
```

### **4. Generate Video**

```python
import time
from google import genai
client = genai.Client(api_key='YOUR_KEY')
operation = client.models.generate_videos(
    model="veo-3.1-generate-preview",
    prompt="A cat playing piano in a jazz club",
)
while not operation.done:
    time.sleep(10)
    operation = client.operations.get(operation)
operation.response.generated_videos[0].video.save("video.mp4")
```

---

**Document compiled on:** November 9, 2025  
**Data sources:** Official Google Gemini API documentation, Python GenAI SDK, and Context7 library documentation

For the most up-to-date information, always refer to the [official Gemini API documentation](https://ai.google.dev/gemini-api/docs).
